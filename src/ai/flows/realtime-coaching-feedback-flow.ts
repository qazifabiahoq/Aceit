'use server';
/**
 * @fileOverview This file implements a Genkit flow for the AI Coach agent,
 * synthesizing speech and vision feedback to provide real-time, actionable vocal advice.
 *
 * - realtimeCoachingFeedback - A function that orchestrates the generation of vocal feedback.
 * - RealtimeCoachingFeedbackInput - The input type for the realtimeCoachingFeedback function.
 * - RealtimeCoachingFeedbackOutput - The return type for the realtimeCoachingFeedback function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';
import {googleAI} from '@genkit-ai/google-genai';
import wav from 'wav';

const RealtimeCoachingFeedbackInputSchema = z.object({
  currentQuestion: z.string().describe('The current interview question being asked.'),
  speechAnalysis: z
    .string()
    .describe('A summary of the user\'s speech performance, including clarity, structure, and relevance.'),
  visionAnalysis: z
    .string()
    .describe('A summary of the user\'s visual cues, including eye contact, facial expressions, and body language.'),
});
export type RealtimeCoachingFeedbackInput = z.infer<typeof RealtimeCoachingFeedbackInputSchema>;

const RealtimeCoachingFeedbackOutputSchema = z.object({
  feedbackText: z.string().describe('The textual, actionable feedback generated by the AI coach.'),
  feedbackAudio: z
    .string()
    .describe('The audio feedback as a base64 encoded WAV data URI (e.g., "data:audio/wav;base64,...").'),
});
export type RealtimeCoachingFeedbackOutput = z.infer<typeof RealtimeCoachingFeedbackOutputSchema>;

const FeedbackTextOutputSchema = z.object({
  feedback: z.string().describe('Concise, actionable feedback for the user.'),
});
type FeedbackTextOutput = z.infer<typeof FeedbackTextOutputSchema>;

const realtimeCoachingFeedbackPrompt = ai.definePrompt({
  name: 'realtimeCoachingFeedbackPrompt',
  input: {schema: RealtimeCoachingFeedbackInputSchema},
  output: {schema: FeedbackTextOutputSchema},
  prompt: `You are an expert interview coach providing real-time feedback.
The user is currently answering the question: "{{{currentQuestion}}}".

Based on the following speech and vision analysis, provide concise, actionable feedback to help the user improve IMMEDIATELY.
Focus on one or two key points they can adjust right now.

Speech Analysis:
{{{speechAnalysis}}}

Vision Analysis:
{{{visionAnalysis}}}

Your feedback should be encouraging, direct, and focused on real-time improvement.`,
});

const realtimeCoachingFeedbackFlow = ai.defineFlow(
  {
    name: 'realtimeCoachingFeedbackFlow',
    inputSchema: RealtimeCoachingFeedbackInputSchema,
    outputSchema: RealtimeCoachingFeedbackOutputSchema,
  },
  async input => {
    // 1. Generate textual feedback using the prompt
    const {output: textOutput} = await realtimeCoachingFeedbackPrompt(input);
    const feedbackText = textOutput!.feedback;

    // 2. Convert textual feedback to speech using TTS model
    const {media} = await ai.generate({
      model: googleAI.model('gemini-2.5-flash-preview-tts'),
      config: {
        responseModalities: ['AUDIO'],
        speechConfig: {
          voiceConfig: {
            prebuiltVoiceConfig: {voiceName: 'Algenib'}, // Using 'Algenib' as an example voice
          },
        },
      },
      prompt: feedbackText,
    });

    if (!media) {
      throw new Error('No audio media returned from TTS model.');
    }

    // Extract base64 encoded audio and convert to WAV
    const audioBuffer = Buffer.from(media.url.substring(media.url.indexOf(',') + 1), 'base64');
    const feedbackAudio = 'data:audio/wav;base64,' + (await toWav(audioBuffer));

    return {
      feedbackText,
      feedbackAudio,
    };
  }
);

export async function realtimeCoachingFeedback(
  input: RealtimeCoachingFeedbackInput
): Promise<RealtimeCoachingFeedbackOutput> {
  return realtimeCoachingFeedbackFlow(input);
}

/**
 * Converts PCM audio data to WAV format.
 *
 * @param pcmData The PCM audio buffer.
 * @param channels Number of audio channels (default: 1).
 * @param rate Sample rate in Hz (default: 24000).
 * @param sampleWidth Sample width in bytes (default: 2).
 * @returns A base64 encoded string of the WAV audio.
 */
async function toWav(
  pcmData: Buffer,
  channels = 1,
  rate = 24000,
  sampleWidth = 2
): Promise<string> {
  return new Promise((resolve, reject) => {
    const writer = new wav.Writer({
      channels,
      sampleRate: rate,
      bitDepth: sampleWidth * 8,
    });

    const bufs = [] as any[];
    writer.on('error', reject);
    writer.on('data', function (d) {
      bufs.push(d);
    });
    writer.on('end', function () {
      resolve(Buffer.concat(bufs).toString('base64'));
    });

    writer.write(pcmData);
    writer.end();
  });
}
